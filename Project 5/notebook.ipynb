{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import BayesianRidge\n# from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n# from sklearn.svm import SVR\n\n#train = pd.read_csv('train_2016_v2.csv')\n#properties = pd.read_csv('properties_2016.csv')\n#train = pd.read_csv('train_2017.csv')\n#properties = pd.read_csv('properties_2017.csv')\n#sample = pd.read_csv('sample_submission.csv')\ntrain = pd.read_csv(r\"../input/train_2016_v2.csv\")\nproperties = pd.read_csv(r\"../input/properties_2016.csv\")\n#train2 = pd.read_csv(r\"../input/train_2017.csv\")\n#props2 = pd.read_csv(r\"../input/properties_2017.csv\")\n#frames1 = [train1,train2]\n#train = pd.concat(frames1)\n#frames2 = [props1,props2]\n#properties = pd.concat(frames2)\nsample = pd.read_csv(r\"../input/sample_submission.csv\")\n\n\n# properties.drop(['basementsqft','buildingclasstypeid','finishedsquarefeet13','storytypeid'], axis=1)\n# properties = properties.select_dtypes(exclude=[object])\n# train = train.loc[:,['parcelid','logerror']].merge(properties,how='left',left_on='parcelid',right_on='parcelid')\n# train_x = train.drop(['parcelid','logerror'],axis=1,inplace=False)\n# train_y = train['logerror']\n# train_y.fillna(-1,inplace=True)\n# train_x.fillna(-1,inplace=True)\n# test = sample.loc[:,['ParcelId']].merge(properties,how='left',left_on='ParcelId',right_on='parcelid')\n# test_x = test.drop(['ParcelId','parcelid'],axis=1,inplace=False)\n# test_x.fillna(-1,inplace=True)\n\n#parameters = {'n_estimators':[15],'n_jobs':[-1],'oob_score':[False]}\n#model = RandomForestRegressor()\n#parameters = {'n_jobs':[-1]}\n#model= LinearRegression()\n#parameters = {}\n#model= BayesianRidge()\n# parameters = {}\n# model = MLPRegressor(hidden_layer_sizes=(5,2 ), activation='logistic', solver='adam', alpha=0.0001, batch_size='auto',\n#                      learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None,\n#                      tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n#                      validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n#parameters = {}\n#model = ExtraTreesRegressor(n_estimators=10, max_features=32,random_state=0)\n#parameters = {}\n#model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n#model = SVR(kernel='linear', C=1e3)\n#model = SVR(kernel='poly', C=1e3, degree=2)\n\n# grid = GridSearchCV(model,param_grid=parameters,scoring='neg_mean_absolute_error',cv=10)\n# grid.fit(train_x,train_y)\n#\n# cv_results = pd.DataFrame(grid.cv_results_)\n# print(cv_results[[\"mean_test_score\"]])\n\n# test_y = grid.predict(test_x)\n# test_y = pd.DataFrame(test_y)\n# test_y[1] = test_y[0]\n# test_y[2] = test_y[0]\n# test_y[3] = test_y[0]\n# test_y[4] = test_y[0]\n# test_y[5] = test_y[0]\n# test_y.columns = [\"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\n# submission = test_y.copy()\n# submission[\"parcelid\"] = sample[\"ParcelId\"].copy()\n# columns = [\"parcelid\",\"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\n# submission = submission[columns]\n# submission.to_csv(\"Prediction\" + '.csv',index=False)\n\n#------------------- lightgbm ---------------------------------#\n#train = pd.read_csv(r\"../input/train_2016_v2.csv\")\n#properties = pd.read_csv(r\"../input/properties_2016.csv\")\n#sample = pd.read_csv(r\"../input/sample_submission.csv\")\n\nfor i, dtype in zip(properties.columns, properties.dtypes):\n    if dtype == np.float64:\n        properties[i] = properties[i].astype(np.float32)\n\ndf_train = train.merge(properties, how='left', on='parcelid')\n\ntrain_x = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\ny_train = df_train['logerror'].values\n\ntrain_columns = train_x.columns\n\nfor i in train_x.dtypes[train_x.dtypes == object].index.values:\n    train_x[i] = (train_x[i] == True)\n\nsplit = 90000\ntrain_x, y_train, x_valid, y_valid = train_x[:split], y_train[:split], train_x[split:], y_train[split:]\ntrain_x = train_x.values.astype(np.float32, copy=False)\nx_valid = x_valid.values.astype(np.float32, copy=False)\n\nd_train = lgb.Dataset(train_x, label=y_train)\nd_valid = lgb.Dataset(x_valid, label=y_valid)\n\nparams = {}\nparams['max_bin'] = 10\nparams['learning_rate'] = 0.0021\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['metric'] = '11'\nparams['sub_feature'] = 0.5\nparams['bagging_fraction'] = 0.85\nparams['bagging_freq'] = 40\nparams['num_leaves'] = 512\nparams['min_data'] = 500\nparams['min_hessian'] = 0.05\n\nwatchlist = [d_valid]\nclf = lgb.train(params, d_train, 430, watchlist)\n\nprint(\"Prepare for the prediction ...\")\nsample['parcelid'] = sample['ParcelId']\ndf_test = sample.merge(properties, on='parcelid', how='left')\nx_test = df_test[train_columns]\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\nx_test = x_test.values.astype(np.float32, copy=False)\n\nclf.reset_parameter({\"num_threads\":1})\np_test = clf.predict(x_test)\n\noutput = pd.read_csv(r\"../input/sample_submission.csv\")\nfor c in output.columns[output.columns != 'ParcelId']:\n    output[c] = p_test\n\noutput.to_csv('Prediction.csv', index=False, float_format='%.4f')",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Prepare for the prediction ...\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:126: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}